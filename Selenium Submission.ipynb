{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f0ec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (4.4.3)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (from selenium) (2022.6.15)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28ebed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries required to Scrape data using Selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eedaaa",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You¶\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eacfd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'E:\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eca85cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.naukri.com/ to scrape data \n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0ecce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Analyst” in “Skill, Designations, Companies” field\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c8a1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Bangalore” in “enter the location” field.\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151e9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then click the search button\n",
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab9c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "job_title =[]\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_reqd = []\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# Scraping Job Location from the given page\n",
    "location_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)   \n",
    "\n",
    "    \n",
    "# Scraping Company Name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_reqd.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a0fa423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking the length of each data scarped before creating the dataframe\n",
    "print(len(job_title), len(job_location), len(company_name), len(experience_reqd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd1ae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- First 10 jobs in “Data Analyst” Job position in “Bangalore” location ---------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company-name</th>\n",
       "      <th>Experience-reqd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business &amp; Data Analyst- Assistant Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>State Street</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Qualitest India Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Clinical Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>LabCorp</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Ahmedabad</td>\n",
       "      <td>milestone internet marketing pvt ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram\\n(WFH du...</td>\n",
       "      <td>Concentrix</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Analyst/Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>JoulestoWatts</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job-title  \\\n",
       "0       Business & Data Analyst- Assistant Manager   \n",
       "1                              Senior Data Analyst   \n",
       "2                              Senior Data Analyst   \n",
       "3                                 Sr. Data Analyst   \n",
       "4                         Sr Clinical Data Analyst   \n",
       "5                                     Data Analyst   \n",
       "6                                     Data Analyst   \n",
       "7  Forecasting Analyst/ Data Scientist (US Client)   \n",
       "8                              Senior Data Analyst   \n",
       "9                    Senior Analyst/Data Scientist   \n",
       "\n",
       "                                        Job-location  \\\n",
       "0        Bangalore/Bengaluru, Hyderabad/Secunderabad   \n",
       "1               Bangalore/Bengaluru(Old Madras Road)   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                          Bangalore/Bengaluru, Pune   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                     Bangalore/Bengaluru, Ahmedabad   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru, Gurgaon/Gurugram\\n(WFH du...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "\n",
       "                              Company-name Experience-reqd  \n",
       "0                             State Street         1-3 Yrs  \n",
       "1                                 KrazyBee         3-6 Yrs  \n",
       "2          Qualitest India Private Limited         5-8 Yrs  \n",
       "3  Global Indian School Education Services        6-11 Yrs  \n",
       "4                                  LabCorp         2-5 Yrs  \n",
       "5     milestone internet marketing pvt ltd         2-7 Yrs  \n",
       "6                                    Bayer         2-5 Yrs  \n",
       "7                               Concentrix         3-8 Yrs  \n",
       "8                                    Optum         5-7 Yrs  \n",
       "9                            JoulestoWatts         6-9 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame for the first 10 jobs for Data Analyst in Bangalore\n",
    "data_analyst = pd.DataFrame({'Job-title':job_title, 'Job-location':job_location,\"Company-name\": company_name, \"Experience-reqd\": experience_reqd})\n",
    "print('-'*15,\"First 10 jobs in “Data Analyst” Job position in “Bangalore” location\",'-'*15)\n",
    "data_analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25cf51",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You¶\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fbd357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'E:\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435539d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.naukri.com/ to scrape data \n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "196528c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Scientist” in “Skill, Designations, Companies” field\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41cbf0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Bangalore” in “enter the location” field.\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fd664c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then click the search button\n",
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "356a10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "job_title_ds =[]\n",
    "job_location_ds = []\n",
    "company_name_ds = []\n",
    "experience_reqd_ds = []\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title_ds.append(title)\n",
    "\n",
    "# Scraping Job Location from the given page\n",
    "location_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location_ds.append(location)   \n",
    "\n",
    "    \n",
    "# Scraping Company Name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name_ds.append(company)\n",
    "    \n",
    "\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_reqd_ds.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc6234cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking the length of each data scarped before creating the dataframe\n",
    "print(len(job_title_ds), len(job_location_ds), len(company_name_ds), len(experience_reqd_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fca3442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- First 10 jobs in “Data Scientist” Job position in “Bangalore” location ---------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company-name</th>\n",
       "      <th>Experience-reqd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Manager - EmTech - Machine Learning - P&amp;T</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>PwC</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, Indore, New...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>11-20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0                                  Lead ML Scientist   \n",
       "1   Senior Manager - EmTech - Machine Learning - P&T   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3     Data scientist _Tata Consultancy Services(Tcs)   \n",
       "4  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "5  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "6                      Tcs Hiring For Data Scientist   \n",
       "7  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "8                   Assistant Manager - Data Science   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job-location  \\\n",
       "0                        Bangalore/Bengaluru, Mumbai   \n",
       "1  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "3  Bangalore/Bengaluru, Kochi/Cochin, Indore, New...   \n",
       "4  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...   \n",
       "5  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "6   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "7  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "8                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "9  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...   \n",
       "\n",
       "                                  Company-name Experience-reqd  \n",
       "0                            Fractal Analytics        6-10 Yrs  \n",
       "1                                          PwC        5-12 Yrs  \n",
       "2                                    Accenture         6-8 Yrs  \n",
       "3              TATA CONSULTANCY SERVICES (TCS)        9-14 Yrs  \n",
       "4                                        Wipro        5-10 Yrs  \n",
       "5  NTT DATA Business Solutions Private Limited         4-9 Yrs  \n",
       "6              TATA CONSULTANCY SERVICES (TCS)         3-8 Yrs  \n",
       "7                                        Wipro       11-20 Yrs  \n",
       "8                                   CitiusTech         5-9 Yrs  \n",
       "9                                ZS Associates         5-8 Yrs  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame for the first 10 jobs for Data Scientist in Bangalore\n",
    "data_scientist = pd.DataFrame({'Job-title':job_title_ds, 'Job-location':job_location_ds,\"Company-name\": company_name_ds, \"Experience-reqd\": experience_reqd_ds})\n",
    "print('-'*15,\"First 10 jobs in “Data Scientist” Job position in “Bangalore” location\",'-'*15)\n",
    "data_scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092c894",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:¶\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80213f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'E:\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdfbe246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.naukri.com/ to scrape data \n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e453b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Scientist” in “Skill, Designations, Companies” field\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "782d4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Delhi/NCR” in “enter the location” field.\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Delhi/NCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc5cee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then click the search button to go to the respective page\n",
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46faba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data based on Salary from “3-6” lakhs\n",
    "filter_sal = driver.find_element(By.XPATH, '//span[@title=\"3-6 Lakhs\"]')\n",
    "filter_sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a362b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "job_title_ds_delhi =[]\n",
    "job_location_ds_delhi = []\n",
    "company_name_ds_delhi = []\n",
    "experience_reqd_ds_delhi = []\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title_ds_delhi.append(title)\n",
    "\n",
    "# Scraping Job Location from the given page\n",
    "location_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location_ds_delhi.append(location)   \n",
    "\n",
    "    \n",
    "# Scraping Company Name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name_ds_delhi.append(company)\n",
    "    \n",
    "\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_reqd_ds_delhi.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa9c4067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n",
      "--------------- First 10 jobs in “Data Scientist” Job position in “Delhi/NCR” location ---------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company-name</th>\n",
       "      <th>Experience-reqd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad, Pune, Chenn...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data science analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CRED</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Risk / Fraud L1</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Risk Platform</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek</td>\n",
       "      <td>5-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "1                               data science analyst   \n",
       "2                   Data Scientist - Risk / Fraud L1   \n",
       "3                                     Data Scientist   \n",
       "4                   Data Scientist - Noida/Bangalore   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                     Data Scientist - Risk Platform   \n",
       "9                                 Decision Scientist   \n",
       "\n",
       "                                        Job-location       Company-name  \\\n",
       "0  New Delhi, Hyderabad/Secunderabad, Pune, Chenn...              Wipro   \n",
       "1                                Bangalore/Bengaluru               CRED   \n",
       "2                                Bangalore/Bengaluru              Gojek   \n",
       "3                                Bangalore/Bengaluru            Infosys   \n",
       "4                         Noida, Bangalore/Bengaluru                EXL   \n",
       "5                                Bangalore/Bengaluru  Applied Materials   \n",
       "6                                Bangalore/Bengaluru  Applied Materials   \n",
       "7                                Bangalore/Bengaluru  Applied Materials   \n",
       "8                                Bangalore/Bengaluru              Gojek   \n",
       "9                                Bangalore/Bengaluru              Gojek   \n",
       "\n",
       "  Experience-reqd  \n",
       "0        5-10 Yrs  \n",
       "1         1-3 Yrs  \n",
       "2         1-2 Yrs  \n",
       "3         2-7 Yrs  \n",
       "4        5-10 Yrs  \n",
       "5         2-4 Yrs  \n",
       "6         4-7 Yrs  \n",
       "7         2-4 Yrs  \n",
       "8        5-11 Yrs  \n",
       "9         4-9 Yrs  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the length of each data scarped before creating the dataframe\n",
    "print(len(job_title_ds_delhi), len(job_location_ds_delhi), len(company_name_ds_delhi), len(experience_reqd_ds_delhi))\n",
    "\n",
    "# Creating the DataFrame for the first 10 jobs for 'Data Scientist' in 'Delhi/NCR'\n",
    "data_scientist_delhi = pd.DataFrame({'Job-title':job_title_ds_delhi, 'Job-location':job_location_ds_delhi,\"Company-name\": company_name_ds_delhi, \"Experience-reqd\": experience_reqd_ds_delhi})\n",
    "print('-'*15,\"First 10 jobs in “Data Scientist” Job position in “Delhi/NCR” location\",'-'*15)\n",
    "data_scientist_delhi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f298ec20",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:¶\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2439469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'E:\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d025e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.flipkart.com/ to scrape data \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f34693ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the login pop-up\n",
    "close_login = driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close_login.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cbbc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “sunglasses” in the search field where “search for products, brands and more” is written\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e910bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search icon after entering the product name\n",
    "search = driver.find_element(By.CLASS_NAME, \"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9dfdd2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "brand_sg =[]\n",
    "product_description_sg = []\n",
    "price_sg = []\n",
    "discount_sg = []\n",
    "\n",
    "\n",
    "# Scarping 100 sunglasses\n",
    "for page in range(0,3):\n",
    "    # Scraping the brand names of the sunglasses\n",
    "    brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for brand in brand_tags:\n",
    "        brand_sg.append(brand.text)\n",
    "        \n",
    "    # Scraping the product description of sunglasses\n",
    "    product_description_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for pr_des in product_description_tags:\n",
    "        product_description_sg.append(pr_des.text)\n",
    "    \n",
    "    # Scraping the 'Price' of the sunglasses\n",
    "    price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for price in price_tags:\n",
    "        price_sg.append(price.text)\n",
    "        \n",
    "    # Scraping the \"Discount\" given for the sunglasses\n",
    "    discount_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]//span')\n",
    "    for discount in discount_tags:\n",
    "        discount_sg.append(discount.text)\n",
    "        \n",
    "    # Moving the next page of sunglasses\n",
    "    next_page = driver.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]//span')\n",
    "    next_page.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "print(len(brand_sg),len(product_description_sg),len(price_sg),len(discount_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c53a35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 100 sunglasses -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (53)</td>\n",
       "      <td>₹281</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Aviator Sunglasses (53)</td>\n",
       "      <td>₹1,229</td>\n",
       "      <td>38% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹224</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹221</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, Riding Glasses Sports, Wrap-around ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description   Price  \\\n",
       "0     Silver Kartz           UV Protection Clubmaster Sunglasses (53)    ₹281   \n",
       "1    VINCENT CHASE  by Lenskart UV Protection Aviator Sunglasses (53)  ₹1,229   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹799   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹639   \n",
       "4           PIRASO              UV Protection Aviator Sunglasses (54)    ₹224   \n",
       "..             ...                                                ...     ...   \n",
       "95   VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹949   \n",
       "96          PIRASO              UV Protection Aviator Sunglasses (54)    ₹221   \n",
       "97  ROZZETTA CRAFT  Polarized, Riding Glasses Sports, Wrap-around ...    ₹499   \n",
       "98      LIZA ANGEL  Riding Glasses, Night Vision Spectacle Sunglas...    ₹199   \n",
       "99   VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹999   \n",
       "\n",
       "   Discount  \n",
       "0   81% off  \n",
       "1   38% off  \n",
       "2   20% off  \n",
       "3   20% off  \n",
       "4   85% off  \n",
       "..      ...  \n",
       "95  52% off  \n",
       "96  86% off  \n",
       "97  75% off  \n",
       "98  80% off  \n",
       "99  50% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 100 sunglasses\n",
    "sunglasses_df = pd.DataFrame({'Brand':brand_sg[0:100], 'Product Description':product_description_sg[0:100],\"Price\":price_sg[0:100], \"Discount\":discount_sg[0:100]})\n",
    "print('-'*25,\"First 100 sunglasses\",'-'*25)\n",
    "sunglasses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c1a0c",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.¶\n",
    "As given in the page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8158e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'E:\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d7ba8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.flipkart.com/ to scrape data \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2931c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the login pop-up\n",
    "close_login = driver.find_element(By.XPATH, '//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close_login.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e7404cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “iphone 11” in the search field\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"iphone 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c8a76152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search icon after entering the product name\n",
    "search = driver.find_element(By.CLASS_NAME, \"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34ead175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the first iphone, then later scraping ratings, review summary and full review\n",
    "iphone11 = driver.find_element(By.CLASS_NAME,\"_4rR01T\")\n",
    "iphone11.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d89e020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "# Creating empty list to scrape required data\n",
    "rating_ip11 =[]\n",
    "review_summary_ip11 =[]\n",
    "full_review_ip11 =[]\n",
    "\n",
    "\n",
    "# Using nested for loop to scrape 100 review details for \"iphone 11\"\n",
    "# Since on the page only 10 reviews are available after inspecting, we need to click on '+' to get more reviews\n",
    "for ip_11 in range(0,20):\n",
    "    # Scraping the rating of \"iphone 11\"\n",
    "    rating = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for rt in rating:\n",
    "        rating_ip11.append(rt.text)\n",
    "        \n",
    "    # Scraping the review summary for \"iphone 11\"\n",
    "    review_summary = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "    for rs in review_summary:\n",
    "        review_summary_ip11.append(rs.text)\n",
    "        \n",
    "    # Scraping the full review for \"iphone 11\"\n",
    "    full_review = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]//div//div')\n",
    "    for fr in full_review:\n",
    "        full_review_ip11.append(fr.text)\n",
    "        \n",
    "    # clicking on the '+' button to get other reviews\n",
    "#     all_reviews.click()\n",
    "#     time.sleep(2)\n",
    "\n",
    "\n",
    "print(len(rating_ip11),len(review_summary_ip11), len(full_review_ip11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27a7fa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 100 reviews of iphone 11 -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rating, Review Summary, Full review]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 100 'iphone 11' reviews\n",
    "ip11_df = pd.DataFrame({'Rating':rating_ip11,'Review Summary':review_summary_ip11[0:100], 'Full review': full_review_ip11[0:100]})\n",
    "print('-'*25,\"First 100 reviews of iphone 11\",'-'*25)\n",
    "ip11_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2293f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code was running properly a day before but now some issue is risen and output is zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087d327",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the¶\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "808ca235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'E:\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35948262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.flipkart.com/ to scrape data \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d96477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the login pop-up\n",
    "close_login = driver.find_element(By.XPATH, '//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close_login.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a76b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “Sneakers” in the search field\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a2c70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search icon after entering the product name\n",
    "search = driver.find_element(By.CLASS_NAME, \"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e59f305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 97 114 110\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "brand_sks =[]\n",
    "product_description_sks = []\n",
    "price_sks = []\n",
    "discount_sks = []\n",
    "\n",
    "\n",
    "# Scarping 100 'Sneakers'\n",
    "for page in range(0,3):\n",
    "    # Scraping the brand names of the 'Sneakers'\n",
    "    brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for brand in brand_tags[0:100]:\n",
    "        brand_sks.append(brand.text)\n",
    "        \n",
    "    # Scraping the product description of 'Sneakers'\n",
    "    product_description_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for pr_des in product_description_tags[0:100]:\n",
    "        product_description_sks.append(pr_des.text)\n",
    "    \n",
    "    # Scraping the 'Price' of the 'Sneakers'\n",
    "    price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for price in price_tags[0:100]:\n",
    "        price_sks.append(price.text)\n",
    "        \n",
    "    # Scraping the \"Discount\" given for the 'Sneakers'\n",
    "    discount_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]//span')\n",
    "    for discount in discount_tags[0:100]:\n",
    "        discount_sks.append(discount.text)\n",
    "        \n",
    "    # Moving the next page of 'Sneakers'\n",
    "    next_page = driver.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]//span')\n",
    "    next_page.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "print(len(brand_sks),len(product_description_sks),len(price_sks),len(discount_sks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64b12dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 100 Sneakers -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (53)</td>\n",
       "      <td>₹281</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Aviator Sunglasses (53)</td>\n",
       "      <td>₹1,229</td>\n",
       "      <td>38% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹224</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹221</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, Riding Glasses Sports, Wrap-around ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description   Price  \\\n",
       "0     Silver Kartz           UV Protection Clubmaster Sunglasses (53)    ₹281   \n",
       "1    VINCENT CHASE  by Lenskart UV Protection Aviator Sunglasses (53)  ₹1,229   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹799   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹639   \n",
       "4           PIRASO              UV Protection Aviator Sunglasses (54)    ₹224   \n",
       "..             ...                                                ...     ...   \n",
       "95   VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹949   \n",
       "96          PIRASO              UV Protection Aviator Sunglasses (54)    ₹221   \n",
       "97  ROZZETTA CRAFT  Polarized, Riding Glasses Sports, Wrap-around ...    ₹499   \n",
       "98      LIZA ANGEL  Riding Glasses, Night Vision Spectacle Sunglas...    ₹199   \n",
       "99   VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹999   \n",
       "\n",
       "   Discount  \n",
       "0   81% off  \n",
       "1   38% off  \n",
       "2   20% off  \n",
       "3   20% off  \n",
       "4   85% off  \n",
       "..      ...  \n",
       "95  52% off  \n",
       "96  86% off  \n",
       "97  75% off  \n",
       "98  80% off  \n",
       "99  50% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 100 'Sneakers'\n",
    "sneakers_df = pd.DataFrame({'Brand':brand_sg[0:100], 'Product Description':product_description_sg[0:100],\"Price\":price_sg[0:100], \"Discount\":discount_sg[0:100]})\n",
    "print('-'*25,\"First 100 Sneakers\",'-'*25)\n",
    "sneakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad55fd",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes¶\n",
    "Set second Price filter and Color filter to “Black”,\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c830a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'E:\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "771fe4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.myntra.com/shoes to scrape data \n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f679a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unable right click on Myntra website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f27b91",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.¶\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "def987f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'E:\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe2d5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.amazon.in/ to scrape data \n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "434e29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “Laptop” in the search field \n",
    "product = driver.find_element(By.XPATH,'//input[@type=\"text\"]')\n",
    "product.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "292eb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search icon after entering the product name\n",
    "search = driver.find_element(By.XPATH, '//input[@id=\"nav-search-submit-button\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9d7586e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the laptops based on “Intel Core i7”\n",
    "filter_laptop = driver.find_element(By.XPATH,'//li[@id=\"p_n_feature_thirteen_browse-bin/12598163031\" and @aria-label=\"Intel Core i7\" ]//span')\n",
    "filter_laptop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5852a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "title_laptop = []\n",
    "ratings_laptop = []\n",
    "price_laptop = []\n",
    "\n",
    "\n",
    "# Scraping the title of laptops\n",
    "title = driver.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for t in title[0:10]:\n",
    "    title_laptop.append(t.text)\n",
    "\n",
    "    \n",
    "# Scraping the ratings of laptop\n",
    "ratings = driver.find_elements(By.XPATH,'//a[@class=\"a-popover-trigger a-declarative\"]')\n",
    "for r in ratings[0:10]:\n",
    "    ratings_laptop.append(r.get_attribute('text'))\n",
    "    \n",
    "\n",
    "# Scraping the price of laptop\n",
    "price = driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "for p in price[0:10]:\n",
    "    price_laptop.append(p.text)\n",
    "    \n",
    "print(len(title_laptop),len(ratings_laptop),len(price_laptop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2a83aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 10 Laptops -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>79,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Pro Intel Core i7 11th G...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>83,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>79,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>82,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>87,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acer Nitro 5 Gaming Laptop/12th Gen Intel Core...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>1,04,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS VivoBook K15 OLED (2021), 15.6-inch FHD O...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Predator Helios 300 12th Gen Intel Core i...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>1,54,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>94,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  3.6 out of 5 stars   \n",
       "1  Lenovo IdeaPad Slim 5 Pro Intel Core i7 11th G...  3.8 out of 5 stars   \n",
       "2  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  3.6 out of 5 stars   \n",
       "3  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...  4.1 out of 5 stars   \n",
       "4  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...  4.1 out of 5 stars   \n",
       "5  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.5 out of 5 stars   \n",
       "6  Acer Nitro 5 Gaming Laptop/12th Gen Intel Core...  4.4 out of 5 stars   \n",
       "7  ASUS VivoBook K15 OLED (2021), 15.6-inch FHD O...  4.2 out of 5 stars   \n",
       "8  Acer Predator Helios 300 12th Gen Intel Core i...  4.5 out of 5 stars   \n",
       "9  Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...  4.4 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    79,490  \n",
       "1    83,500  \n",
       "2    79,490  \n",
       "3    82,200  \n",
       "4    87,990  \n",
       "5    57,990  \n",
       "6  1,04,990  \n",
       "7    82,990  \n",
       "8  1,54,990  \n",
       "9    94,990  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 10 'Laptops'\n",
    "sneakers_df = pd.DataFrame({'Title':title_laptop[0:10], 'Ratings':ratings_laptop[0:10],\"Price\":price_laptop[0:10]})\n",
    "print('-'*25,\"First 10 Laptops\",'-'*25)\n",
    "sneakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128fd65c",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida¶\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ce95284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'E:\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0411560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.ambitionbox.com/ to scrape data \n",
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b4433526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the Job option\n",
    "job_op = driver.find_element(By.CLASS_NAME, 'navItemLink')\n",
    "job_op.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d9d6e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In place of “Search by Designations, Companies, Skills” enter “Data Scientist”\n",
    "post = driver.find_element(By.XPATH, '//input[@title=\"Enter Designation, Company or a Skill\"]')\n",
    "post.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "55078f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on search button.\n",
    "search = driver.find_element(By.XPATH, '//button[@class=\"ab_btn search-btn round\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eaa1f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on location\n",
    "location = driver.find_element(By.XPATH, '//div[@title=\"Location\"]')\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1fb598bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering the location 'Noida'\n",
    "noida = driver.find_element(By.XPATH, '//input[@placeholder=\"Search locations\"]')\n",
    "noida.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12004bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on Noida\n",
    "search1 = driver.find_element(By.XPATH, '//label[@for=\"location_Noida\"]')\n",
    "search1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ddc66100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for the data\n",
    "name_company = []\n",
    "job_post_days =[]\n",
    "rating_company =[]\n",
    "\n",
    "\n",
    "# Scraping the name of the company\n",
    "company = driver.find_elements(By.XPATH, '//p[@class=\"company body-medium\"]')\n",
    "for c in company:\n",
    "    name_company.append(c.text)\n",
    "    \n",
    "# Scraping the Number of days ago when job was posted \n",
    "days = driver.find_elements(By.XPATH, '//span[@class=\"body-small-l\"]')\n",
    "for d in days:\n",
    "    a = []\n",
    "    b = []\n",
    "    for i in range(len(days)):\n",
    "        if i % 2 == 0:\n",
    "            a.append(days[i].text)\n",
    "        elif i % 2 == 1:\n",
    "            b.append(days[i].text)\n",
    "job_post_days = a\n",
    "    \n",
    "# Scraping the Rating of the Company\n",
    "rtg = driver.find_elements(By.XPATH, '//span[@class=\"body-small\"]')\n",
    "for r in rtg:\n",
    "    rating_company.append(r.text)\n",
    "    \n",
    "print(len(name_company),len(job_post_days),len(rating_company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d9773f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 10 job results -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job posted days</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>8d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>23hr ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>15d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>28d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SOPRA STERIA INDIA LIMITED</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Company Job posted days Rating\n",
       "0                         CBRE South Asia Pvt Ltd          8d ago    4.3\n",
       "1                   GENPACT India Private Limited        23hr ago    4.0\n",
       "2                                         Genpact          3d ago    4.0\n",
       "3        Ericsson India Global Services Pvt. Ltd.         18d ago    4.3\n",
       "4                   GENPACT India Private Limited         11d ago    4.0\n",
       "5  Optum Global Solutions (India) Private Limited         15d ago    4.1\n",
       "6  Optum Global Solutions (India) Private Limited         16d ago    4.1\n",
       "7        Ericsson India Global Services Pvt. Ltd.         28d ago    4.3\n",
       "8                      SOPRA STERIA INDIA LIMITED         17d ago    4.2\n",
       "9                EXL Services.com ( I ) Pvt. Ltd.         17d ago    3.9"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for first 10 job results \n",
    "jobs_df = pd.DataFrame({'Company':name_company, 'Job posted days':job_post_days,\"Rating\":rating_company})\n",
    "print('-'*25,\"First 10 job results\",'-'*25)\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e60ae",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.¶\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "webpage https://www.ambitionbox.com/\n",
    "Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f33354b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'E:\\driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d812f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.ambitionbox.com/ to scrape data \n",
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9896261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the Salaries option\n",
    "salary_op = driver.find_element(By.XPATH, '/html/body/div[1]/nav[2]/div/ul/li[3]/a')\n",
    "action = webdriver.ActionChains(driver)\n",
    "action.move_to_element(salary_op)\n",
    "action.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ac5c0ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuation on the Salaries option\n",
    "salary_browse = driver.find_element(By.XPATH, '//a[@title=\"Browse salaries\"]')\n",
    "salary_browse.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8719be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In place of “Search Job Profile” enters “Data Scientist”\n",
    "data_sc = driver.find_element(By.XPATH, '//input[@type=\"searchbox\"]')\n",
    "data_sc.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dcce010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then click on “Data Scientist”\n",
    "ds = driver.find_element(By.XPATH, '/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p')\n",
    "ds.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9f3e81e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Creating the empty list for the required data to be scraped\n",
    "company_n = []\n",
    "total_salary_record=[]\n",
    "avg_salary = []\n",
    "min_salary=[]\n",
    "max_salary=[]\n",
    "exp_reqd =[]\n",
    "\n",
    "# Getting the names of the company\n",
    "cn = driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for n in cn[0:10]:\n",
    "    cd = n.text.split()[:-10]\n",
    "    name = ''\n",
    "    company_n.append(name.join(cd))\n",
    "\n",
    "# Getting the total salary record of the company\n",
    "cn = driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for n in cn[0:10]:\n",
    "    s = n.text.split()[-2:]\n",
    "    total_salary_record.append(s[0])\n",
    "\n",
    "# Getting the average salary of the company\n",
    "avg_s = driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for av in avg_s:\n",
    "    avg_salary.append(av.text)\n",
    "\n",
    "# Getting the Maximum and Minimum salary of the company\n",
    "max_min_s = driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]')\n",
    "for mm in range(len(max_min_s)):\n",
    "    if mm % 2 == 0:\n",
    "        min_salary.append(max_min_s[mm].text)\n",
    "    elif mm % 2 == 1:\n",
    "        max_salary.append(max_min_s[mm].text)\n",
    "        \n",
    "# Getting the experience required\n",
    "exp = driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]')\n",
    "for er in exp[0:10]:\n",
    "    ex = er.text.split()[:-4]\n",
    "    exp_reqd.append(ex[0]+' '+ex[1])\n",
    "\n",
    "print(len(company_n),len(total_salary_record),len(avg_salary),len(max_salary),len(min_salary),len(exp_reqd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "35eef463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- First 10 the salary data for Data Scientist designation  ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Total salary record</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Experince Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>22</td>\n",
       "      <td>₹ 31.7L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbInbev</td>\n",
       "      <td>53</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>48</td>\n",
       "      <td>₹ 16.5L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>33</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>1-2 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FractalAnalytics</td>\n",
       "      <td>109</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TigerAnalytics</td>\n",
       "      <td>65</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LegatoHealthTechnologies</td>\n",
       "      <td>11</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>12</td>\n",
       "      <td>₹ 14.1L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>3 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>91</td>\n",
       "      <td>₹ 13.6L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FordMotor</td>\n",
       "      <td>21</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name Total salary record Average Salary Maximum Salary  \\\n",
       "0                   Walmart                  22        ₹ 31.7L        ₹ 45.0L   \n",
       "1                   AbInbev                  53        ₹ 19.7L        ₹ 25.5L   \n",
       "2                     Optum                  48        ₹ 16.5L        ₹ 22.6L   \n",
       "3                        ZS                  33        ₹ 15.7L        ₹ 22.0L   \n",
       "4          FractalAnalytics                 109        ₹ 15.2L        ₹ 23.0L   \n",
       "5            TigerAnalytics                  65        ₹ 14.7L        ₹ 20.0L   \n",
       "6  LegatoHealthTechnologies                  11        ₹ 14.5L        ₹ 20.0L   \n",
       "7                  Tredence                  12        ₹ 14.1L        ₹ 17.5L   \n",
       "8              UnitedHealth                  91        ₹ 13.6L        ₹ 20.5L   \n",
       "9                 FordMotor                  21        ₹ 13.5L        ₹ 18.0L   \n",
       "\n",
       "  Minimum Salary Experince Required  \n",
       "0        ₹ 25.0L            3-4 yrs  \n",
       "1        ₹ 15.0L            2-4 yrs  \n",
       "2        ₹ 11.0L            2-4 yrs  \n",
       "3        ₹ 11.0L            1-2 yrs  \n",
       "4         ₹ 9.0L            2-4 yrs  \n",
       "5         ₹ 9.0L            2-4 yrs  \n",
       "6        ₹ 11.0L              4 yrs  \n",
       "7         ₹ 8.8L              3 yrs  \n",
       "8         ₹ 8.0L            2-4 yrs  \n",
       "9        ₹ 10.0L            3-4 yrs  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for first 10 the salary data for Data Scientist designation \n",
    "salary_df = pd.DataFrame({'Company Name':company_n, 'Total salary record':total_salary_record,'Average Salary':avg_salary,\n",
    "                         'Maximum Salary':max_salary,'Minimum Salary':min_salary,'Experince Required':exp_reqd})\n",
    "print('-'*10,\"First 10 the salary data for Data Scientist designation \",'-'*10)\n",
    "salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c58deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
